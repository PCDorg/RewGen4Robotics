# Code Tip:
# - The reward function must have the signature: def custom_reward_function(obs, action, done, env):
# - Use only NumPy and standard Python (no external libraries beyond NumPy).
# - The environment might be wrapped (e.g., by TimeLimit); always access the base environment with env.unwrapped.
# - Access the goal position using env.unwrapped.goal.
# - The observation may be a dictionary. If so, extract the actual observation array using obs = obs.get('observation', obs).
# - Assume the first two elements of the observation array correspond to the ant's x and y positions,
#   and the next two correspond to the velocities.
# - Provide a bonus when the ant is within a threshold of the goal, and penalize if the episode ends before reaching the goal.
# -the reward function  should return only the reward (a float). This is causing the error because stable_baselines3 expects the reward to be a single number, not a tuple.