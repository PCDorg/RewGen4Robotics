[2025-03-30 14:16:43,067][root][INFO] - Using results directory: /home/ken2/PCD/outputs/2025-03-30/14-16-42/results/2025-03-30
[2025-03-30 14:16:43,069][root][INFO] - ========== Starting Iteration 1/5 ==========
[2025-03-30 14:16:43,069][root][INFO] - Iteration 1/5: LLM Attempt 1/10
[2025-03-30 14:16:43,069][root][INFO] - Generating new reward function with LLM...
[2025-03-30 14:16:43,071][root][INFO] - Sending request to OpenAI API...
[2025-03-30 14:17:00,599][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-03-30 14:17:00,661][root][INFO] - Received response from LLM.
[2025-03-30 14:17:00,662][root][INFO] - Iteration 1/5: Successfully generated and extracted reward code.
[2025-03-30 14:17:00,662][root][INFO] - Iteration 1/5: Saving generated reward function to: /home/ken2/PCD/outputs/2025-03-30/14-16-42/results/2025-03-30/reward_function_0.py
[2025-03-30 14:17:00,665][root][INFO] - Iteration 1/5: Starting training and evaluation...
[2025-03-30 14:17:00,665][root][INFO] - Iteration 1: Creating environment with reward from: /home/ken2/PCD/outputs/2025-03-30/14-16-42/results/2025-03-30/reward_function_0.py
[2025-03-30 14:17:01,100][root][INFO] - Iteration 1: Initializing PPO model. Logging TensorBoard to: /home/ken2/PCD/outputs/2025-03-30/14-16-42/results/2025-03-30/tensorboard_logs/iteration_0
[2025-03-30 14:17:04,398][root][INFO] - Iteration 1: Starting training for 100000 timesteps...
[2025-03-30 14:17:06,184][root][ERROR] - Error during training/evaluation in Iteration 1: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices
[2025-03-30 14:17:06,194][root][ERROR] - Traceback (most recent call last):
  File "/home/ken2/PCD/gen.py", line 139, in train_and_evaluate
    model.learn(total_timesteps=total_timesteps, tb_log_name="PPO", reset_num_timesteps=False)
  File "/home/ken2/.local/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 311, in learn
    return super().learn(
  File "/home/ken2/.local/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 323, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
  File "/home/ken2/.local/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 218, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
  File "/home/ken2/.local/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 207, in step
    return self.step_wait()
  File "/home/ken2/.local/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 59, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]
  File "/home/ken2/.local/lib/python3.10/site-packages/stable_baselines3/common/monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
  File "/home/ken2/PCD/envs/fetchReach.py", line 23, in step
    custom_reward = self.custom_reward_function(next_obs, action, terminated, self.env)
  File "/home/ken2/PCD/outputs/2025-03-30/14-16-42/results/2025-03-30/reward_function_0.py", line 37, in custom_reward_function
    goal_distance = np.linalg.norm(env.goal - obs['achieved_goal'])
IndexError: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices

[2025-03-30 14:17:06,194][root][WARNING] - Iteration 1/5: Training/Evaluation failed. Error logged.
[2025-03-30 14:17:06,194][root][INFO] - Iteration 1/5: Logging results to /home/ken2/PCD/outputs/2025-03-30/14-16-42/results/2025-03-30/conversation_history.md
[2025-03-30 14:17:06,195][root][INFO] - ========== Finished Iteration 1/5 ==========

[2025-03-30 14:17:06,195][root][INFO] - ========== Starting Iteration 2/5 ==========
[2025-03-30 14:17:06,195][root][INFO] - Iteration 2/5: LLM Attempt 1/10
[2025-03-30 14:17:06,195][root][INFO] - Generating new reward function with LLM...
[2025-03-30 14:17:06,202][root][INFO] - Sending request to OpenAI API...
[2025-03-30 14:17:27,737][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-03-30 14:17:27,808][root][INFO] - Received response from LLM.
[2025-03-30 14:17:27,809][root][INFO] - Iteration 2/5: Successfully generated and extracted reward code.
[2025-03-30 14:17:27,810][root][INFO] - Iteration 2/5: Saving generated reward function to: /home/ken2/PCD/outputs/2025-03-30/14-16-42/results/2025-03-30/reward_function_1.py
[2025-03-30 14:17:27,812][root][INFO] - Iteration 2/5: Starting training and evaluation...
[2025-03-30 14:17:27,812][root][INFO] - Iteration 2: Creating environment with reward from: /home/ken2/PCD/outputs/2025-03-30/14-16-42/results/2025-03-30/reward_function_1.py
[2025-03-30 14:17:28,081][root][INFO] - Iteration 2: Initializing PPO model. Logging TensorBoard to: /home/ken2/PCD/outputs/2025-03-30/14-16-42/results/2025-03-30/tensorboard_logs/iteration_1
[2025-03-30 14:17:28,224][root][INFO] - Iteration 2: Starting training for 100000 timesteps...
